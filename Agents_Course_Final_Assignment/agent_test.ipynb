{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295eb96a",
   "metadata": {},
   "source": [
    "# Lang Graph Based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Constants\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea758cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two integers.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero.\")\n",
    "    return a / b\n",
    "\n",
    "@tool\n",
    "def youtube_transcript(video_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the transcript (captions) of a YouTube video, if available.\n",
    "    This tool extracts and returns the full transcript text from the given YouTube video URL. It is helpful for answering questions based on what is said in a video, such as summarizing content or pulling out spoken facts. It does not interpret visual elements, only spoken audio with captions.\n",
    "    \"\"\"\n",
    "    docs = YoutubeLoader.from_youtube_url(video_url).load()\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a query and return maximum 2 results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query.\"\"\"\n",
    "    print(f\"üîç Tool 'wiki_search' invoked with query: {query}\")\n",
    "    search_docs = WikipediaLoader(query=query, load_max_docs=2).load()\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ])\n",
    "    return {\"wiki_results\": formatted_search_docs}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search Tavily Web for a query and return maximum 3 results from the web.\"\"\"\n",
    "    print(f\"üîç Tool 'web_search' invoked with query: {query}\")\n",
    "    search_tool = TavilySearchResults(max_results=3)\n",
    "    search_results = search_tool.invoke(input=query)\n",
    "\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"<Document source=\\\"{r.get('source', '')}\\\"/>\\n{r.get('content', '')}\\n</Document>\"\n",
    "        for r in search_results\n",
    "    )\n",
    "    return formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#System Prompt\n",
    "\n",
    "# Load metadata.jsonl\n",
    "import json\n",
    "# Load the metadata.jsonl file\n",
    "with open('metadata.jsonl', 'r') as jsonl_file:\n",
    "    json_list = list(jsonl_file)\n",
    "\n",
    "json_QA = []\n",
    "for json_str in json_list:\n",
    "    json_data = json.loads(json_str)\n",
    "    json_QA.append(json_data)\n",
    "\n",
    "random_samples = random.sample(json_QA, 3)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful AI agent. After using tools or reasoning through a question, always return the answer on the last line in the format:\n",
    "FINAL ANSWER: <answer>\n",
    "\n",
    "You must reason step-by-step, use available tools when helpful, and produce a precise final answer.\n",
    "\n",
    "==========================\n",
    "üîÅ ANSWERING STRATEGY\n",
    "==========================\n",
    "\n",
    "- Prioritize grounded evidence from tool outputs or the conversation context.\n",
    "- Do NOT speculate if evidence is missing.\n",
    "- Use web search if unable to answer using specific tools.\n",
    "\n",
    "==========================\n",
    "üß† REASONING FORMAT\n",
    "==========================\n",
    "\n",
    "You must show your thought process, then conclude with this template:\n",
    "\n",
    "FINAL ANSWER: [A number OR short string OR comma-separated list of values]\n",
    "\n",
    "==========================\n",
    "üö® FINAL ANSWER RULES\n",
    "==========================\n",
    "\n",
    "‚ùå NEVER include explanation after FINAL ANSWER.\n",
    "‚ùå NEVER include units (e.g., $, %, km) unless specifically requested.\n",
    "‚ùå NEVER use commas in numbers (write 1000 instead of 1,000).\n",
    "‚ùå NEVER use abbreviations or articles unless explicitly required.\n",
    "‚ùå NEVER include icons or emojis before, within, or after the FINAL ANSWER\n",
    "\n",
    "Answer types:\n",
    "- Number ‚Üí FINAL ANSWER: 42\n",
    "- String ‚Üí FINAL ANSWER: Paris\n",
    "- Year ‚Üí FINAL ANSWER: 2009\n",
    "- List ‚Üí FINAL ANSWER: blue, green, red\n",
    "\n",
    "‚ö†Ô∏è BEFORE you give your FINAL ANSWER:\n",
    "- Reread the question carefully.\n",
    "- Identify **exactly** what entity type is being asked (e.g., name, number, city, year).\n",
    "- Ensure the answer is **directly tied to the question**, not just something mentioned during reasoning.\n",
    "- Be careful to NOT give intermediate entities (e.g., actor name when the question asks for the character).\n",
    "\n",
    "==========================\n",
    "‚úÖ FINAL CHECKLIST\n",
    "==========================\n",
    "Before giving FINAL ANSWER:\n",
    "- [ ] Did I use all relevant tools and their results or grounded information?\n",
    "- [ ] Is my answer the specific format and type requested?\n",
    "- [ ] Did I avoid guessing or using unrelated intermediate facts?\n",
    "- [ ] Did I double check that my FINAL ANSWER matches the exact thing asked in the question?\n",
    "\n",
    "==========================\n",
    "üìò EXAMPLES\n",
    "==========================\n",
    "Below are some examples showing how to approach questions step by step.\n",
    "\"\"\"\n",
    "\n",
    "for i, samples in enumerate(random_samples):\n",
    "    system_prompt += f\"\\nQuestion {i+1}: {samples['Question']}\\nSteps:\\n{samples['Annotator Metadata']['Steps']}\\nTools:\\n{samples['Annotator Metadata']['Tools']}\\nFinal Answer: {samples['Final answer']}\\n\"\n",
    "system_prompt += \"\\n==========================\\n\"\n",
    "system_prompt += \"Now, please answer the following question step by step.\\n\"\n",
    "\n",
    "# save the system_prompt to a file\n",
    "with open('system_prompt.txt', 'w') as f:\n",
    "    f.write(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09924be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Agent\n",
    "tools = [\n",
    "    multiply,\n",
    "    add,\n",
    "    subtract,\n",
    "    divide,\n",
    "    web_search,\n",
    "    wiki_search,\n",
    "    youtube_transcript\n",
    "]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "sys_msg = SystemMessage(content=system_prompt)\n",
    "\n",
    "# Assistant Node\n",
    "def assistant_node(state: MessagesState):\n",
    "    print(\"---Assistant Node---\")\n",
    "    result = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    print(f\"üéØ LLM Output: {result.content}\")\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# Build Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant_node\", assistant_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant_node\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant_node\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant_node\")\n",
    "\n",
    "agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61049c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is 2 + 2?\"\n",
    "messages = [HumanMessage(content=question)]\n",
    "messages = agent.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ce194",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_API_URL = \"https://agents-course-unit4-scoring.hf.space\"\n",
    "\n",
    "api_url = DEFAULT_API_URL\n",
    "questions_url = f\"{api_url}/questions\"\n",
    "\n",
    "print(f\"Fetching questions from: {questions_url}\")\n",
    "try:\n",
    "    response = requests.get(questions_url, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    questions_data = response.json()\n",
    "    if not questions_data:\n",
    "            print(\"Fetched questions list is empty.\")\n",
    "    print(f\"Fetched {len(questions_data)} questions.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching questions: {e}\")\n",
    "except requests.exceptions.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON response from questions endpoint: {e}\")\n",
    "        print(f\"Response text: {response.text[:500]}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred fetching questions: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_BACKOFF = 30  # seconds\n",
    "MAX_RETRIES = 5\n",
    "\n",
    "def extract_final_answer(submitted_text: str) -> str:\n",
    "    match = re.search(r\"FINAL ANSWER:\\s*(.*)\", submitted_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"N/A\"\n",
    "\n",
    "def run_agent_with_retries(task_id, question_text):\n",
    "    attempt = 0\n",
    "    while attempt < MAX_RETRIES:\n",
    "        try:\n",
    "            print(f\"\\nTask ID: {task_id} - Attempt {attempt + 1} - Question: {question_text}\")\n",
    "            messages = agent.invoke({\"messages\": [HumanMessage(content=question_text)]}, debug=False)\n",
    "            full_response = messages[\"messages\"][-1].content\n",
    "            submitted_answer = extract_final_answer(full_response)\n",
    "            print(f\"‚úÖ Submitted Answer: {submitted_answer}\")\n",
    "            return submitted_answer  # successful run\n",
    "\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            error_msg = str(e)\n",
    "            print(f\"‚ö†Ô∏è Error on task {task_id}, attempt {attempt}: {error_msg}\")\n",
    "\n",
    "            if \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    wait_time = BASE_BACKOFF * (2 ** (attempt - 1)) + random.uniform(0, 1)\n",
    "                    print(f\"‚è≥ Rate limit hit. Retrying in {wait_time:.2f} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(\"‚ùå Max retries reached.\")\n",
    "                    return f\"AGENT ERROR: Rate limit (after {MAX_RETRIES} attempts)\"\n",
    "            else:\n",
    "                print(\"‚ùå Non-retryable error.\")\n",
    "                return f\"AGENT ERROR: {error_msg}\"\n",
    "    return \"AGENT ERROR: Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution loop\n",
    "results_log = []\n",
    "answers_payload = []\n",
    "print(f\"Running agent on {len(questions_data)} questions...\")\n",
    "\n",
    "for item in questions_data[:]:  \n",
    "    task_id = item.get(\"task_id\")\n",
    "    question_text = item.get(\"question\")\n",
    "\n",
    "    if not task_id or question_text is None:\n",
    "        print(f\"Skipping item with missing task_id or question: {item}\")\n",
    "        continue\n",
    "\n",
    "    submitted_answer = run_agent_with_retries(task_id, question_text)\n",
    "\n",
    "    answers_payload.append({\"task_id\": task_id, \"submitted_answer\": submitted_answer})\n",
    "    results_log.append({\n",
    "        \"Task ID\": task_id,\n",
    "        \"Question\": question_text,\n",
    "        \"Submitted Answer\": submitted_answer\n",
    "    })\n",
    "\n",
    "if not answers_payload:\n",
    "    print(\"‚ùå Agent did not produce any answers to submit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results_log:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "with open('metadata.jsonl', 'r') as f:\n",
    "    metadata_entries = [json.loads(line) for line in f.readlines()]\n",
    "metadata_lookup = {entry['task_id']: entry for entry in metadata_entries}\n",
    "\n",
    "# Backtesting results\n",
    "print(\"\\n=== üîç Backtest Results ===\\n\")\n",
    "correct_count = 0\n",
    "total = 0\n",
    "\n",
    "for result in results_log:\n",
    "    task_id = result[\"Task ID\"]\n",
    "    submitted = result[\"Submitted Answer\"].strip().replace(\"FINAL ANSWER: \", \"\").strip()\n",
    "    expected = metadata_lookup.get(task_id, {}).get(\"Final answer\", \"N/A\")\n",
    "    \n",
    "    is_match = submitted.lower() == expected.lower()\n",
    "    match_status = \"‚úÖ MATCH\" if is_match else \"‚ùå MISMATCH\"\n",
    "    if is_match:\n",
    "        correct_count += 1\n",
    "    total += 1\n",
    "\n",
    "    print(f\"Task ID: {task_id}\")\n",
    "    print(f\"Your Answer: {submitted}\")\n",
    "    print(f\"Expected Answer: {expected}\")\n",
    "    print(f\"Result: {match_status}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Summary\n",
    "accuracy = (correct_count / total * 100) if total else 0\n",
    "print(f\"\\nSummary: {correct_count}/{total} correct ({accuracy:.2f}% accuracy)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
